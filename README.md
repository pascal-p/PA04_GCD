---
title: "Getting and Cleaning Data Project"
date: "July, 2018"
author: Pascal P
output:
  html_document:
    toc: true
    number_sections: true
    df_print: paged
    highlight: zenburn
    theme: simplex
---

# Introduction
  This repository contains the resulting work I did in the context of the project for the Coursera course "Getting and Cleaning Data Project".  
  This file is also provided as an HTML file (`README.html`).
  
# Project instructions 
  These can be found at https://www.coursera.org/learn/data-cleaning/peer/FIZtT/getting-and-cleaning-data-course-project  
  In particular the section "Getting and Cleaning Data Course Project" details what is expected.
  
# Codebook
  The codebook `CodeBook.md` summarizes where to find the original (raw) data and lists the variables used for the final data set 
  The provided html version of the codebook may be easier to read (check `CodeBook.html`).
  
# Code and data transformation
  This part explains the 5 step process I followed to obtain the final tidy data set.  
  The R code for this is available in script file `run_analysis.R`

  **Remarks**:  
  
  - Opted to load only the required files per step (instead of pre-loading everything). So it is not until step 3 that I have everything. This is by no mean mandatory.   
  - Spelling for data set is also (sometimes) dataset.  
  - A data set is represented by a data frame, I tend to use these two terms interchangeably.  

## Loading and merging training and test data sets
  The following steps were followed to obtain the consolidated data frame in memory.
  
  - Put the data into a subdirectory called `data/UCI_HAR_Dataset`
  - Noticed that in the X files, numbers were separated by space.
  - Checked the following files ignoring sub directory `Inertial Signals/` (for each set) and determined their dimensions (denoted by [nrows x ncols]):  
  
  `test/`  
    - `subject_test.txt [2947 x   1]`  
    - `X_test.txt       [2947 x 561]`  
    - `y_test.txt       [2947 x   1]`   
  `train/`  
    - `subject_train.txt [7352 x   1]`   
    - `X_train.txt       [7352 x 561]`  
    - `y_train.txt       [7352 x   1]`    
  
  - To find out these dimensions I ran the pipeline Unix command (based on default separator space):  
```
  awk '{print NF}' data/UCI_HAR_Dataset/test/X_test.txt | sort | uniq -c
  2947 561
```
  This tells us that all 2947 lines have 561 columns. Ran the same command on all the files mentionned above.
  This is not strictly necessary, but I wanted to understand a bit more the data before starting anything with R.
  Running A GNU/Linux system, which as any Unix flavor was designed to work with text file makes it really handy.

  - Loading all the train files and merge (or consolidate, using cbind function) them together, gives a dataframe with dimension `7352 x 563`   
  Remark: the 2 additional columns ("Subject" and "Activity") were prepended to the dataframe (therefore located at indexes 1 and 2). 
  
  - Loading all the test files and merge (or consolidate, using cbind function them together, gives a dataframe with dimension `2947 x 563`  
  Same remark as above for the 2 additional columns.

  - Merging or consolidating the two dataframes (using rbind function) gives a dataframe with dimension `10299 x 563`
  
  **Summary of R code for this part**  
  
  - load data set with function `read.table`, using separator set to `""`  
  - use `cbind` to combine all columns together for test and for training sets  
  - use `rbind` to combine the two dataframe into one  
  
  **Remark**: For details on how to load and merge these files, cf. `R` script `run_analysis.R`, in particular:  
    functions: `performStep1` which calls: `loadFile`, `loadAndCombineDS` and `combineDS`


## Extract only mean and standard deviation measurement 
  The following steps were followed to obtain the data frame restricted to the specific columns (as per requirement).  
  
  - Read the features from file `data/UCI_HAR_Dataset/features.txt`- dimension `561 x 1`
  
  - Extract from features those whose names are matching `-mean()`, `-meanFreq()` or `-std()`, using `grep` function and a regular expression (`"-(mean.*|std)\\(\\)"`). *Please note this is my relative interpretation*.  
  This produces a vector of indexes.  
  Remark: The possible range of indexes in the vector is `[1, 561]`
  
  - All indexes in the result vector need to be offset-ed by 2, in order to be applied onto our consolidated dataframe (with `563` columns) as we want to keep the two firat columns ("Subject" and "Activity").
  
  - Finally we select the target column from dataframe (given all the indexes), using `sapply` function, this gives a new dataframe of dimension `10299 x 81`  
  
  **Remark**: For details on how to select mean and standard deviation columns, cf. `R` script `run_analysis.R`, in particular:  
    functions: `performStep2` which calls: `loadLabels`, `filterFeatures` and `applyFilterDS`

  
## Use descriptive activity names
  Column number 2 (Activity) of our current data set is a numeric column with integer values from 1 to 6. 
  The aim here is to replace these indexes with the strings from the activity labels.  
  
  - After loading the activity labels into memory, I opted to meta-function `sapply` to mutate the column number 2.  

  **Remark**: For details on how to achieve this step, cf. `R` script `run_analysis.R`, in particular:  
    functions: `performStep3` which calls: `setActivityName`


## Label the data with descriptive variables names
  In this step, the aim is to tidy up the variable names.  
  
  - First, replace all the columns names (up to now labelled with V1.1, ..V2, V3, ...) with the names provided in `features.txt` loaded in step 2. 
  Also named the first (left) columns: Subject and Activity (in this order).
  
  - Tidy up the column names removing characters such as `-`, `_`, `(`, `)`... expand and capitalize where appropriate.  
  so for example names starting with 't' are expanded to 'time' ('f' to 'freq').
  
  **Remark**: For details on how to achieve this step, cf. `R` script `run_analysis.R`, in particular:  
    functions: `performStep4` which calls: `setLabelOnDS` and `cleanLabelsForDS`.  
   
   
## Second independent tidy data set with average of each variable
  In this part, the aim is to create a second data set. For this part I opted for the package `dplyr`

  - Load the `dplyr` package and convert current data frame in data table
  
  - Then apply a pipeline grouping by Subject and Activity prior to summarize on the given groups
  
  - Write resulting table into file `tidy_data_summary_180x81.txt`, the name here explicits the final dimensions
  
  **Remark**: For details on how to achieve this step, cf. `R` script `run_analysis.R`, in particular:  
    functions: `performStep5` which calls: `summarizeData` 
    
    
# About `r` script `run_analysis.R` and the result data file

## How to run it?
  - Assuming you have :
    - a working directory were you have downloaded / cloned the `R` script `run_analysis.R`
    - downloaded and uncompressed data set (cf. paragraph "Original Data" above) into a sub directory `data/` and renamed the resulting sub-directory (from `UCI HAR Dataset`) to `UCI_HAR_Dataset`.  
  
  - Launch r-studio, go to your working directory.  
  
  - Execute: 
```r
rm(list=ls())
source("run_analysis.R")
```
  
  - Console output (for reference):
```r
[1] "1 - Loading and combining all files to single dataset"
[1] "dim dataset: 10299x563"
[1] "2a - Load the features"
[1] "dim dataset: 561x1"
[1] "2b - Get the subset Mean/Std and keep 2 first columns"
[1] "dim dataset: 10299x81"
[1] "3 - Replace 2nd column with activity names (lowercase them)"
[1] "dim dataset: 10299x81"
[1] "4 - Name the columns of dataset (in order) and tidy them up"
[1] "dim dataset: 10299x81"
[1] "5 - Create a second, independent tidy data"
[1] "dim dataset: 180x81"
```

  - Result file `tidy_data_summary_180x81.txt` should be available.  
  **Please note, this text file is semi-column separated**.
  
## Some details about file `tidy_data_summary_180x81.txt`
```r
> str(mytab)
Classes ‘grouped_df’, ‘tbl_df’, ‘tbl’ and 'data.frame':	180 obs. of  81 variables:
 $ Subject                    : int  1 1 1 1 1 1 2 2 2 2 ...
 $ Activity                   : chr  "laying" "sitting" "standing" "walking" ...
 $ TimeBodyAccMean.X          : num  0.222 0.261 0.279 0.277 0.289 ...
 $ TimeBodyAccMean.Y          : num  -0.04051 -0.00131 -0.01614 -0.01738 -0.00992 ...
 $ TimeBodyAccMean.Z          : num  -0.113 -0.105 -0.111 -0.111 -0.108 ...
 $ TimeBodyAccStd.X           : num  -0.928 -0.977 -0.996 -0.284 0.03 ...
 $ TimeBodyAccStd.Y           : num  -0.8368 -0.9226 -0.9732 0.1145 -0.0319 ...
 $ TimeBodyAccStd.Z           : num  -0.826 -0.94 -0.98 -0.26 -0.23 ...
 $ TimeGravityAccMean.X       : num  -0.249 0.832 0.943 0.935 0.932 ...
 $ TimeGravityAccMean.Y       : num  0.706 0.204 -0.273 -0.282 -0.267 ...
 $ TimeGravityAccMean.Z       : num  0.4458 0.332 0.0135 -0.0681 -0.0621 ...
 $ TimeGravityAccStd.X        : num  -0.897 -0.968 -0.994 -0.977 -0.951 ...
 $ TimeGravityAccStd.Y        : num  -0.908 -0.936 -0.981 -0.971 -0.937 ...
 $ TimeGravityAccStd.Z        : num  -0.852 -0.949 -0.976 -0.948 -0.896 ...
 $ TimeBodyAccJerkMean.X      : num  0.0811 0.0775 0.0754 0.074 0.0542 ...
 $ TimeBodyAccJerkMean.Y      : num  0.003838 -0.000619 0.007976 0.028272 0.02965 ...
 $ TimeBodyAccJerkMean.Z      : num  0.01083 -0.00337 -0.00369 -0.00417 -0.01097 ...
 $ TimeBodyAccJerkStd.X       : num  -0.9585 -0.9864 -0.9946 -0.1136 -0.0123 ...
 $ TimeBodyAccJerkStd.Y       : num  -0.924 -0.981 -0.986 0.067 -0.102 ...
 $ TimeBodyAccJerkStd.Z       : num  -0.955 -0.988 -0.992 -0.503 -0.346 ...
 $ TimeBodyGyroMean.X         : num  -0.0166 -0.0454 -0.024 -0.0418 -0.0351 ...
 $ TimeBodyGyroMean.Y         : num  -0.0645 -0.0919 -0.0594 -0.0695 -0.0909 ...
 $ TimeBodyGyroMean.Z         : num  0.1487 0.0629 0.0748 0.0849 0.0901 ...
 $ TimeBodyGyroStd.X          : num  -0.874 -0.977 -0.987 -0.474 -0.458 ...
 $ TimeBodyGyroStd.Y          : num  -0.9511 -0.9665 -0.9877 -0.0546 -0.1263 ...
 $ TimeBodyGyroStd.Z          : num  -0.908 -0.941 -0.981 -0.344 -0.125 ...
 $ TimeBodyGyroJerkMean.X     : num  -0.1073 -0.0937 -0.0996 -0.09 -0.074 ...
 $ TimeBodyGyroJerkMean.Y     : num  -0.0415 -0.0402 -0.0441 -0.0398 -0.044 ...
 $ TimeBodyGyroJerkMean.Z     : num  -0.0741 -0.0467 -0.049 -0.0461 -0.027 ...
 $ TimeBodyGyroJerkStd.X      : num  -0.919 -0.992 -0.993 -0.207 -0.487 ...
 $ TimeBodyGyroJerkStd.Y      : num  -0.968 -0.99 -0.995 -0.304 -0.239 ...
 $ TimeBodyGyroJerkStd.Z      : num  -0.958 -0.988 -0.992 -0.404 -0.269 ...
 $ TimeBodyAccMagMean         : num  -0.8419 -0.9485 -0.9843 -0.137 0.0272 ...
 $ TimeBodyAccMagStd          : num  -0.7951 -0.9271 -0.9819 -0.2197 0.0199 ...
 $ TimeGravityAccMagMean      : num  -0.8419 -0.9485 -0.9843 -0.137 0.0272 ...
 $ TimeGravityAccMagStd       : num  -0.7951 -0.9271 -0.9819 -0.2197 0.0199 ...
 $ TimeBodyAccJerkMagMean     : num  -0.9544 -0.9874 -0.9924 -0.1414 -0.0894 ...
 $ TimeBodyAccJerkMagStd      : num  -0.9282 -0.9841 -0.9931 -0.0745 -0.0258 ...
 $ TimeBodyGyroMagMean        : num  -0.8748 -0.9309 -0.9765 -0.161 -0.0757 ...
 $ TimeBodyGyroMagStd         : num  -0.819 -0.935 -0.979 -0.187 -0.226 ...
 $ TimeBodyGyroJerkMagMean    : num  -0.963 -0.992 -0.995 -0.299 -0.295 ...
 $ TimeBodyGyroJerkMagStd     : num  -0.936 -0.988 -0.995 -0.325 -0.307 ...
 $ FreqBodyAccMean.X          : num  -0.9391 -0.9796 -0.9952 -0.2028 0.0382 ...
 $ FreqBodyAccMean.Y          : num  -0.86707 -0.94408 -0.97707 0.08971 0.00155 ...
 $ FreqBodyAccMean.Z          : num  -0.883 -0.959 -0.985 -0.332 -0.226 ...
 $ FreqBodyAccStd.X           : num  -0.9244 -0.9764 -0.996 -0.3191 0.0243 ...
 $ FreqBodyAccStd.Y           : num  -0.834 -0.917 -0.972 0.056 -0.113 ...
 $ FreqBodyAccStd.Z           : num  -0.813 -0.934 -0.978 -0.28 -0.298 ...
 $ FreqBodyAccMeanFreq.X      : num  -0.1588 -0.0495 0.0865 -0.2075 -0.3074 ...
 $ FreqBodyAccMeanFreq.Y      : num  0.0975 0.0759 0.1175 0.1131 0.0632 ...
 $ FreqBodyAccMeanFreq.Z      : num  0.0894 0.2388 0.2449 0.0497 0.2943 ...
 $ FreqBodyAccJerkMean.X      : num  -0.9571 -0.9866 -0.9946 -0.1705 -0.0277 ...
 $ FreqBodyAccJerkMean.Y      : num  -0.9225 -0.9816 -0.9854 -0.0352 -0.1287 ...
 $ FreqBodyAccJerkMean.Z      : num  -0.948 -0.986 -0.991 -0.469 -0.288 ...
 $ FreqBodyAccJerkStd.X       : num  -0.9642 -0.9875 -0.9951 -0.1336 -0.0863 ...
 $ FreqBodyAccJerkStd.Y       : num  -0.932 -0.983 -0.987 0.107 -0.135 ...
 $ FreqBodyAccJerkStd.Z       : num  -0.961 -0.988 -0.992 -0.535 -0.402 ...
 $ FreqBodyAccJerkMeanFreq.X  : num  0.132 0.257 0.314 -0.209 -0.253 ...
 $ FreqBodyAccJerkMeanFreq.Y  : num  0.0245 0.0475 0.0392 -0.3862 -0.3376 ...
 $ FreqBodyAccJerkMeanFreq.Z  : num  0.02439 0.09239 0.13858 -0.18553 0.00937 ...
 $ FreqBodyGyroMean.X         : num  -0.85 -0.976 -0.986 -0.339 -0.352 ...
 $ FreqBodyGyroMean.Y         : num  -0.9522 -0.9758 -0.989 -0.1031 -0.0557 ...
 $ FreqBodyGyroMean.Z         : num  -0.9093 -0.9513 -0.9808 -0.2559 -0.0319 ...
 $ FreqBodyGyroStd.X          : num  -0.882 -0.978 -0.987 -0.517 -0.495 ...
 $ FreqBodyGyroStd.Y          : num  -0.9512 -0.9623 -0.9871 -0.0335 -0.1814 ...
 $ FreqBodyGyroStd.Z          : num  -0.917 -0.944 -0.982 -0.437 -0.238 ...
 $ FreqBodyGyroMeanFreq.X     : num  -0.00355 0.18915 -0.12029 0.01478 -0.10045 ...
 $ FreqBodyGyroMeanFreq.Y     : num  -0.0915 0.0631 -0.0447 -0.0658 0.0826 ...
 $ FreqBodyGyroMeanFreq.Z     : num  0.010458 -0.029784 0.100608 0.000773 -0.075676 ...
 $ FreqBodyAccMagMean         : num  -0.8618 -0.9478 -0.9854 -0.1286 0.0966 ...
 $ FreqBodyAccMagStd          : num  -0.798 -0.928 -0.982 -0.398 -0.187 ...
 $ FreqBodyAccMagMeanFreq     : num  0.0864 0.2367 0.2846 0.1906 0.1192 ...
 $ FreqBodyAccJerkMagMean     : num  -0.9333 -0.9853 -0.9925 -0.0571 0.0262 ...
 $ FreqBodyAccJerkMagStd      : num  -0.922 -0.982 -0.993 -0.103 -0.104 ...
 $ FreqBodyAccJerkMagMeanFreq : num  0.2664 0.3519 0.4222 0.0938 0.0765 ...
 $ FreqBodyGyroMagMean        : num  -0.862 -0.958 -0.985 -0.199 -0.186 ...
 $ FreqBodyGyroMagStd         : num  -0.824 -0.932 -0.978 -0.321 -0.398 ...
 $ FreqBodyGyroMagMeanFreq    : num  -0.139775 -0.000262 -0.028606 0.268844 0.349614 ...
 $ FreqBodyGyroJerkMagMean    : num  -0.942 -0.99 -0.995 -0.319 -0.282 ...
 $ FreqBodyGyroJerkMagStd     : num  -0.933 -0.987 -0.995 -0.382 -0.392 ...
 $ FreqBodyGyroJerkMagMeanFreq: num  0.176 0.185 0.334 0.191 0.19 ...
 - attr(*, "vars")= chr "Subject"
 - attr(*, "drop")= logi TRUE
```

## Loading result data file 

  Execute (note: separator is the semi-column):
```r
dfr <- read.table("tidy_data_summary_180x81.txt", sep=';', dec = ".", header=TRUE)

```
  
  
# Reference
  Coursera Course - *Getting and Cleaning Data*: https://www.coursera.org/learn/data-cleaning/home/welcome
